# AI Configuration Examples
# Copy these to your .env file and customize as needed

# =============================================================================
# AI Provider Configuration
# =============================================================================

# Default AI provider: openai or ollama
AI_PROVIDER=openai

# =============================================================================
# OpenAI Configuration (for production/cloud)
# =============================================================================
AI_OPENAI_CHAT_MODEL=gpt-4o-mini
AI_OPENAI_EXTRACTION_MODEL=gpt-4o-mini
AI_OPENAI_SUBJECT_MODEL=gpt-4o-mini
AI_OPENAI_TEMPERATURE=0.7
AI_OPENAI_MAX_TOKENS=1200

# =============================================================================
# Ollama Configuration (for local development)
# =============================================================================
# AI_PROVIDER=ollama
# AI_OLLAMA_CHAT_MODEL=llama3.2:8b
# AI_OLLAMA_EXTRACTION_MODEL=llama3.2:8b
# AI_OLLAMA_SUBJECT_MODEL=llama3.2:3b
# AI_OLLAMA_TEMPERATURE=0.7
# AI_OLLAMA_MAX_TOKENS=1200
# AI_OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# Environment-Specific Recommendations:
# =============================================================================

# Local Development - Low Resource (8GB RAM):
# AI_OLLAMA_CHAT_MODEL=llama3.2:3b
# AI_OLLAMA_EXTRACTION_MODEL=llama3.2:3b
# AI_OLLAMA_SUBJECT_MODEL=llama3.2:3b

# Local Development - Medium Resource (16GB RAM):
# AI_OLLAMA_CHAT_MODEL=llama3.2:8b
# AI_OLLAMA_EXTRACTION_MODEL=llama3.2:8b
# AI_OLLAMA_SUBJECT_MODEL=llama3.2:3b

# Local Development - High Resource (32GB+ RAM or GPU):
# AI_OLLAMA_CHAT_MODEL=qwen2.5:14b
# AI_OLLAMA_EXTRACTION_MODEL=llama3.2:8b
# AI_OLLAMA_SUBJECT_MODEL=llama3.2:3b

# Production - Cost Optimized:
# AI_OPENAI_CHAT_MODEL=gpt-4o-mini
# AI_OPENAI_EXTRACTION_MODEL=gpt-4o-mini
# AI_OPENAI_SUBJECT_MODEL=gpt-4o-mini

# Production - Performance Optimized:
# AI_OPENAI_CHAT_MODEL=gpt-4o
# AI_OPENAI_EXTRACTION_MODEL=gpt-4o-mini
# AI_OPENAI_SUBJECT_MODEL=gpt-4o-mini