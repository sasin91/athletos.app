# AI Configuration for your system (14GB RAM)
AI_PROVIDER=ollama

# Ollama models (optimized for your setup)
AI_OLLAMA_CHAT_MODEL=llama3.1:8b
AI_OLLAMA_EXTRACTION_MODEL=llama3.1:8b  
AI_OLLAMA_SUBJECT_MODEL=llama3.2:3b
AI_OLLAMA_TEMPERATURE=0.7
AI_OLLAMA_MAX_TOKENS=1200
AI_OLLAMA_BASE_URL=http://localhost:11434